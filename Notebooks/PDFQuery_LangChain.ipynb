{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgOhk8U4Rpl"
      },
      "source": [
        "# Quickstart: Querying PDF With Astra and LangChain\n",
        "\n",
        "### A question-answering demo using Astra DB and LangChain, powered by Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqfJKgRM4Rpo"
      },
      "source": [
        "#### Pre-requisites:\n",
        "\n",
        "You need a **_Serverless Cassandra with Vector Search_** database on [Astra DB](https://astra.datastax.com) to run this demo. As outlined in more detail [here](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html#_prepare_for_using_your_vector_database), you should get a DB Token with role _Database Administrator_ and copy your Database ID: these connection parameters are needed momentarily.\n",
        "\n",
        "You also need an [OpenAI API Key](https://cassio.org/start_here/#llm-access) for this demo to work.\n",
        "\n",
        "#### What you will do:\n",
        "\n",
        "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
        "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_FeN-Ep4Rpp"
      },
      "source": [
        "Install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk0qUhJUQrkO",
        "outputId": "f0ec1a6c-08c7-4ac2-f4ad-e55bad80c590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken langchain-HuggingFace langchain-community langchain-groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQN-L2J4Rpq"
      },
      "source": [
        "Import the packages you'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "V4qBIihE4Rpq"
      },
      "outputs": [],
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
        "from langchain_groq import ChatGroq\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIs76OPQ6JyD",
        "outputId": "76bf4367-133d-4662-c90a-5fd693a31da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1itBNL1v6N9-"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2UauiC4Rpr"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqpM6I854Rpr"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"your api keys\" # enter the \"AstraCS:...\" string found in in your Token JSON file\n",
        "ASTRA_DB_ID = \"your api keys\" # enter your Database ID\n",
        "\n",
        "groq_API_KEY = \"your api keys\" # enter your OpenAI key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "waVKJW-n6jqJ"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('Paper.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "42BKuFRO6meP"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "vR41Iq-4ZHnG",
        "outputId": "0092bed7-ac0a-45e1-fb8f-08f4b10f3fac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/359246513\\nSoftware-Engineering Design Patterns for Machine Learning Applications\\nArticle \\xa0\\xa0 in\\xa0\\xa0Comput er · Mar ch 2022\\nDOI: 10.1109/MC.2021.3137227\\nCITATIONS\\n58READS\\n2,898\\n7 author s, including:\\nHironori W ashiz aki\\nWaseda Univ ersity\\n445 PUBLICA TIONS \\xa0\\xa0\\xa03,670  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nYann-Gaël Guéhéneuc\\nConc ordia Univ ersity\\n368 PUBLICA TIONS \\xa0\\xa0\\xa011,389  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nHironori T akeuchi\\nMusashi Univ ersity\\n34 PUBLICA TIONS \\xa0\\xa0\\xa0181 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nSatoshi Ok uda\\nPrimestyle c o.\\n8 PUBLICA TIONS \\xa0\\xa0\\xa081 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Yann-Gaël Guéhéneuc  on 17 May 2022.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.Software Engineering Patterns for Machine Learning\\nApplications (SEP4MLA)\\nHIRONORI WASHIZAKI, Waseda University / National Institute of Informatics / System Information / eXmotion\\nFOUTSE KHOMH, Polytechnique Montréal\\nYANN-GAËL GUÉHÉNEUC, Concordia University\\nTo grasp the landscape of software engineering patterns for machine learning (ML) applications, a systematic literature review of both\\nacademic and gray literature is conducted to collect good and bad software-engineering practices in the form of patterns and anti-patterns for\\nML applications. From the 32 scholarly documents and 48 gray documents identiﬁed, we extracted 12 ML architecture patterns, 13 ML design\\npatterns, and 8 ML anti-patterns. From these 33 ML patterns, we describe three major ML architecture patterns (“Data Lake”, “Distinguish\\nBusiness Logic from ML Models”, and “Microservice Architecture”) and one ML design pattern (“ML Versioning”) in the standard pattern\\nformat so that practitioners can (re)use them in their contexts.\\nCategories and Subject Descriptors: I.2.6 [ Artiﬁcial Intelligence ]: Learning— Machine learning ; D.2.11 [ Software Engineering ]: Software\\nArchitectures— Patterns\\nAdditional Key Words and Phrases: Machine learning patterns\\nACM Reference Format:\\nWashizaki, H. Khomh, F . and Guéhéneuc, Y .-G. 2020. Core Machine Learning Architecture and Design Patterns. HILLSIDE Proc. of Conf. on\\nPattern Lang. of Prog. 0 (March 2020), 10 pages.\\n1. INTRODUCTION\\nResearchers and practitioners studying best practices strive to provide patterns that address software complexity\\nand quality issues in any type of software system. Recently, software systems with machine learning (ML)\\nalgorithms have become very popular. Because these ML applications are complex, they should beneﬁt from\\npatterns that codify good/bad architectural and design practices during development. To help developers ensure\\nquality, such practices are often formalized as architecture and design patterns, which encapsulate reusable\\nsolutions to common problems within a given context.\\nTo grasp the landscape of software-engineering architecture and design patterns for machine-learning appli-\\ncations (SEP4MLA), we performed a systematic literature review (SLR) of both academic and gray literature to\\nThe authors would like to thank Prof. Naoshi Uchihira, Mr. Norihiko Ishitani, Dr. Takuo Doi, Dr. Shunichiro Suenaga, Mr. Y asuhiro Watanabe,\\nand Prof. Kazunori Sakamoto for their help. This work was supported by JST -Mirai Program Grant Number JP18077318, Japan.\\nAuthor’s address: H. Washizaki, 3-4-1 Okubo, Shinjuku-ku, Tokyo, Japan; email: washizaki@waseda.jp; F . Khomh, Polytechnique\\nMontréal, QC, Canada; email: foutse.khomh@polymtl.ca; Y.-G. Guéhéneuc, Concordia University, Montréal, QC, Canada; email: yann-\\ngael.gueheneuc@concordia.ca\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\\ncopies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page.\\nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission. A preliminary version of\\nthis paper was presented in a writers’ workshop at the 9thAsian Conference on Pattern Languages of Programs in 2020 (AsianPLoP’20).\\nAsianPLoP’20, MARCH 4–6, Taipei, Taiwan. Copyright 2020 is held by the author(s). HILLSIDE 978-1-941652-03-9Separation of Concerns \\nand Modularization of \\nML Components \\nHandshake T est the infrastructure independently \\nfrom the machine learning \\nReuse Code between Training \\nPipeline and Serving Pipeline Data-Algorithm-\\nServing-Evaluator Closed-Loop Intelligence \\nCanary ModelDaisy Architecture \\nEvent-driven ML MicroservicesMicroservice Architecture \\nData Lake \\nKappa Architecture Lambda Architecture \\nReexamine Experimental \\nBranches Periodically Parameter-Server \\nAbstraction \\nDescriptive Data Type \\nfor Rich Information Decouple Training Pipeline \\nfrom Production Pipeline ML VersioningDistinguish Business \\nLogic from \\nML Models \\nGateway Routing \\nArchitecture Undeclared Consumers \\nMultiple-Language \\nSmell \\nPlain-Old-Data \\nType Smell Abstraction Debt \\nPipeline Jungles \\nGlue Code Big Ass Script \\nArchitecture \\nAnti-pattern Architecture pattern \\nDesign pattern X Y   X can mitigate Y . \\nX Y    X uses Y in its solution. \\nX Y    X and Y can be combined.\\nX Y    X is similar to Y . Legend Design Holistically about Data \\nCollection and Feature Extraction \\nDead Experimental \\nCodepaths Federated Learning\\nSecure Aggregation Architecture \\npatterns \\nDesign \\npatterns \\nWrap Black-Box Packages \\ninto Common APIs Isolate and Validate \\nOutput of Model \\nX Y Patterns used by multiple participants.Fig. 1. Map to classify and relate patterns.\\ncollect SE good (bad) patterns for ML application systems and software [Washizaki et al .2019]. From the 32\\nscholarly documents and 48 gray documents identiﬁed in the SLR, 12 ML architecture patterns, 13 ML design\\npatterns, 3 ML anti-architecture patterns, and 5 ML anti-design patterns were extracted. Figure 1 shows a pattern\\nmap of these patterns and their relationships [Washizaki et al. 2020].\\nA survey of software-engineering and machine-learning developers at a workshop revealed that there are 7\\nmajor ML architectural patterns and 5 major ML design patterns among these 33 SEP4MLA. Multiple developers\\nanswered that they used the following ML architecture patterns: “Data-Algorithm-Serving-Evaluator”, “Data Lake“,\\n“Distinguish Business Logic from ML Models”, “Microservice Architecture”, “Event-driven ML Microservices”,\\n“Lambda Architecture”, and “Parameter-Server Abstraction” [Washizaki et al .2020]. They also used the following\\nML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Versioning”, “Test Infrastructure\\nIndependently from ML ”, and “Wrap Black-box Packages into Common APIs” [Washizaki et al. 2020].\\nSince not all of the identiﬁed patterns are well documented in the standard pattern format, which includes clear\\nproblem statements and corresponding solution descriptions, herein we describe three major ML architecture\\npatterns and one ML design pattern in the standard pattern format so that practitioners can (re)use them in their\\ncontexts.\\n2. DATA LAKE\\n2.1 Source\\n[Gollapudi 2016; Menon 2017; Singh 2019]\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 22.2 Intent\\nCollect raw data for as long as possible and offer access to analytic algorithms, like ML algorithms.\\n2.3 Context\\nA lot of real-world data/information cannot be expressed easily through relational schemas. This data can be\\ndocuments (e.g., images), key/value pairs (e.g., users’ encrypted passwords) graphs (e.g., UML class diagrams),\\nor time series (e.g., temperatures from sensors). Although this data is not necessarily “big” data, it must be stored\\nto be analyzed asynchronously.\\n2.4 Problem\\nIn the traditional Data Warehouse architecture, all data is read from various sources by an ETL (Extract/Transform/Load)\\ntool, and is well structured based on a simpliﬁed data model to gain all the advantages of a data warehouse such\\nas fast and efﬁcient query processing [Daehn 2017]. In other words, semantics ﬁrst and content later [Daehn 2017].\\nIn practice, neither the types of analyses that will be performed nor the adopted frameworks can be foreseen.\\n2.5 Solution\\nFigure 2 shows the entire structure to solve the problem. Data, which ranges from structured to unstructured,\\nshould be stored as “raw” as possible into a data storage called a \"Data Lake\". A data lake should allow parallel\\nanalyses of different types of data with various frameworks. Thus, a data lake should facilitate efﬁcient (time, space)\\nwriting of data from the data sources (e.g., sensors) and efﬁcient, parallel reading of the data for ML frameworks.\\nTo realize these features, the data lake must contain historical data and support the insert functionality.\\nThe approach of the data lake is the opposite of a data Warehouse. That is, content ﬁrst and semantics later\\n[Daehn 2017]. By giving up the update and delete functionalities, the overhead of an active database can be\\navoided without sacriﬁcing anything else [Daehn 2017].\\n2.6 Example\\nApache Hadoop1and Azure Data Lake Storage Gen22implement data lakes. In addition, Amazon Simple Storage\\nService (S3)3can be used to implement a data lake, and Amazon provides a service called \"AWS Lake Formation\"4\\nto set up a secure data lake in days.\\n2.7 Discussion\\nData lakes must have clear access controls to allow certain users to write data and other users to read data. For\\nexample, sensors can write (not read), while a control system can read (not write). Analyses applying on a data\\nlake must ﬁrst transfer (while transforming) the relevant data from the data lake into a data warehouse. Then the\\ndata warehouse can be completely rebuilt using a transformation tool such as Apache Spark5.\\n2.8 Related Patterns\\n“Distinguish Business Logic from ML Models” (see Section 3) and Gateway Routing Architecture (not described\\nhere).\\n1https://hadoop.apache.org/\\n2https://azure.microsoft.com/solutions/data-lake/\\n3https://aws.amazon.com/s3/\\n4https://aws.amazon.com/lake-formation/\\n5https://spark.apache.org/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 3Unstructured \\ndata Structured \\ndata Data \\nsource Data \\nsource \\nML framework Data \\nsource Data \\nsource \\nML framework ML framework Other data \\nanalytics Insert-only \\ndata storage \\nTransformation tool \\nData \\nwarehouse Fig. 2. Structure of the Data Lake pattern\\n3. DISTINGUISH BUSINESS LOGIC FROM ML MODELS\\n3.1 Source\\n[Y okoyama 2019]\\n3.2 Intent\\nSeparate the overall business logic of the ML application from the actual used ML models.\\n3.3 Context\\nML applications often use different ML frameworks and associated models (trained in previous, off-line phases).\\nThe frameworks and models play roles in the wider business logic.\\n3.4 Problem\\nThe business logic depends on the results of the models, which may fail for a variety of reasons (as the rest of the\\nbusiness logic can too). Hence, the overall business logic should be isolated as much as possible from the ML\\nmodels. This way, they can be changed/overridden when necessary without impacting the rest of the business\\nlogic.\\n3.5 Solution\\nFigure 3 shows the entire structure to solve the problem.\\n(1)Separate the business logic and the inference engine, loosely coupling the business logic and ML-speciﬁc\\ndataﬂows.\\n(2)Use loggers to monitor the behavior of the ML models.\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 4(3)Set-up alarms for changes in the data distributions that may invalidate the ML models throughout the execution\\nof the ML application.\\nData Layer Logic Layer Presentation Layer \\nUser \\nInterface Database \\nData \\nCollection Data Lake Business \\nLogic \\nData \\nProcessing \\nInference \\nEngine Real World Business Logic Specific ML Specific \\nArchitectural Layers \\nDeployed as ML System Business Logic Data Flow \\nML Runtime Data Flow \\nML Development Data Flow Legend \\nFig. 3. Structure of the Distinguish Business Logic from ML Model pattern.\\n3.6 Example\\nFigure 4 presents an example of the pattern in a Slack-based Chatbot system [Washizaki et al .2020]. In the\\nsystem, there is clear separation between the Chatbot service (as the business logic) and the underlying ML\\ncomponents.\\n3.7 Discussion\\nThis pattern distinguishes failures from the business logic and the ML models so that ML models can be changed\\nwithout impacting the rest of the logic.\\n3.8 Related Patterns\\n“Gateway Routing Architecture” and “Closed-loop Intelligence” (not described here).\\n4. MICROSERVICE ARCHITECTURE\\n4.1 Source\\n[Everett 2018; Smith 2017]\\n4.2 Intent\\nDeﬁne consistent input and output data and provide well-deﬁned services to use for ML frameworks.\\n4.3 Context\\nML applications often use different ML frameworks, which are developed independently by ML researchers. ML\\nresearchers are experts in ML but not in the development of frameworks. Moreover, each team of researchers has\\na different idea about their working frameworks. Thus, ML frameworks are heterogeneous in terms of forms (APIs)\\nand contents (data structures, algorithms).\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 5Data Layer Logic Layer Presentation Layer \\nUser Interface \\n(Chatbot UI) \\nWeb App \\nFront-end Slack Business Logic \\n(Chatbot Logic) \\nWeb App \\nBack-end Slack \\nData Collection \\n(Dataset) \\nDatasets Nagoya Univ. \\nConversation \\nCorpus Data Processing \\n(Text to Vector Transformer) \\nNN Model \\npre- and post-\\nprocessing TensorFlow \\nInference Engine \\n(Language Model) \\nNN Model TensorFlow Database \\n(Previous Q&A Store) \\nDB Server (None) \\nData Lake \\n(V ectorized Corpus) \\nWord \\nV ector TensorFlow\\n(Text) Users \\nData \\nSource Input \\nOutput \\nDatasets \\nML Input ML Output \\nArchitectural Elements \\n(Example Role as Chatbot) \\nWhat How \\nBusiness Logic Data Flow \\nML Development Data Flow ML Runtime Data Flow Input Data \\nOutput Data \\nInput Data \\nDatasets Word \\nVector \\nLegend Fig. 4. Example of a Chatbot System Architecture by applying the “Distinguish Business Logic from ML Model” pattern.\\nA wide variety of these frameworks are available in open-source at places like mloss.org , or from in-house\\ncode, proprietary packages, and cloud-based platforms. ML applications may use one framework but later change\\nfor another framework.\\n4.4 Problem\\nIt is impossible to be familiar with all ML frameworks. In addition, data scientists may be unable to install and run\\nthese frameworks locally. Thus, ML applications may be conﬁned to “known” ML frameworks, and opportunities for\\nmore appropriate frameworks may be missed.\\n4.5 Solution\\nFigure 5 shows the entire structure to solve the problem. Data scientists working with or providing ML frameworks\\ncan make these frameworks available through micro-services. Micro-services are ﬁne-grained and accessible\\nthrough simple protocols. Thus, data scientists can offer access to their ML frameworks through micro-services so\\nthat any ML application can beneﬁt from their frameworks without having to (1) install them and (2) maintain them\\nwhen new versions are available.\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 6Client (User Interface) \\nML framework \\nDB ML service ML service Routing \\nservice \\nMicroservice \\nDB Microservice\\nDB Fig. 5. Structure of the Microservices Architecture pattern.\\n4.6 Example\\nAmazon SageMaker6(see also AWS DeepRacer7)\\n4.7 Discussion\\nThe beneﬁt of microservices is that data scientists, who may not be experts in software engineering, do not have to\\nworry about installing/maintaining ML frameworks. They can also use the same set of microservices in different ML\\napplications. Similarly, microservices can be used by different, competing ML applications. Hence, microservice\\nproviders can capitalize on their investment.\\nUnlike “Wrap Black-Box Packages into Common APIs”, ML applications depend on microservices and cannot\\nimmediately replace one ML framework with another (unless the microservice provider offers different frameworks).\\nThus, ML applications become dependent upon one service provider.\\n4.8 Related Patterns\\n“Daisy Architecture”, “Event-driven ML Microservices”, “Wrap Black-box Packages into Common APIs”, and\\n‘Separation of Concerns and Modularization of ML Components” (not described here).\\n5. ML VERSIONING\\n5.1 Source\\n[Wu et al. 2019; Amershi et al. 2019; Sculley et al. 2015]\\n5.2 Intent\\nVersion ML models like any other software artifacts are tested for regressions and replication ease.\\n5.3 Context\\nML applications may use (1) several models that (2) can change over time (new training).\\n6https://aws.amazon.com/sagemaker/\\n7https://aws.amazon.com/deepracer/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 75.4 Problem\\nML models and their different versions may change the behavior of the overall ML application.\\n5.5 Solution\\nFigure 6 shows the entire structure to solve the problem. Record the ML model structure, training dataset, training\\nsystem and analytical code to ensure a reproducible training process and an inference process. Similar to other\\nsoftware artifacts, ML models should be versioned so that they can be tested and rolled back in case of regression.\\nML model \\nDataset \\nCode Version \\nVersion Control and Configuration \\nManagement …\\n…\\nFig. 6. Structure of the ML Versioning pattern.\\n5.6 Example\\nIn the Eclipse Foundation library DP4J, models can be saved and loaded from the ﬁle system using the org.\\ndeeplearning4j.rl4j.policy.DQNPolicy.save(String) andorg.deeplearning4j.rl4j.policy.DQNPolicy.\\nload(String) methods. These methods can be used not only during training/production but also during versioning\\nto store models and version them as any other software artifacts.\\n5.7 Discussions\\nTo the best of our knowledge, previous works have not studied the performance and the sustainability of serialized\\nML models. It is unknown whether saving/loading models has a negative impact on the performances of ML\\napplications. In addition, the long-term abilities to load and use ML models with new versions of (different) ML\\nframeworks are unknown.\\nAlthough versioning the control dataset, training system, analytical code, and corresponding ML models is\\nrecommended to ensure the reproducibility, versioning all of them in a sophisticated and systematic manner\\ncan be difﬁcult due to the size of the dataset and complicated conﬁgurations among the hyperparameters,\\ntraining/inference code, etc. Two layers of version control can mitigate the issue by handling code and metadata\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 8(of dataset and ML models) in a code storage such as Git8, and handling large dataset and ML models in a data\\nstorage such as DVC (Data Version Control)9[Wu 2019].\\n5.8 Related Patterns\\n“Test the Infrastructure Independently from the Machine Learning” and “Canary Model” (not described here).\\n6. CONCLUSION\\nHerein three major ML architecture patterns (“Data Lake“, “Distinguish Business Logic from ML Models”, and\\n“Microservice Architecture”) and one major ML design pattern (“ML Versioning”) are described. These pattern are\\nfrom a set of 33 patterns identiﬁed through a SLR. In the future, we plan to write all 33 patterns in the standard\\npattern format to help developers adopt good practices and avoid bad practices described by these patterns.\\nAcknowledgement\\nWe are grateful to shepherd Prof. Nien Lin Hsueh for the careful review that improve this paper. We thank Mr.\\nHiromu Uchida, Prof. Naoshi Uchihira, Mr. Norihiko Ishitani, Dr. Takuo Doi, Dr. Shunichiro Suenaga, Mr. Y asuhiro\\nWatanabe and Prof. Kazunori Sakamoto for their help. This work was supported by JST-Mirai Program Grant\\nNumber JP18077318, Japan.\\nReceived December 2019; revised ; accepted\\nREFERENCES\\nSaleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald C. Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and\\nThomas Zimmermann. 2019. Software engineering for machine learning: a case study. In Proceedings of the 41st International Conference\\non Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2019, Montreal, QC, Canada, May 25-31, 2019 . 291–300.\\nDOI:http://dx.doi.org/10.1109/ICSE-SEIP.2019.00042\\nWerner Daehn. 2017. A future-proof Big Data Architecture. https://blogs.sap.com/2017/10/10/\\nfuture-proof-big-data-architecture/ . (October 2017).\\nJulian Everett. 2018. Daisy Architecture. https://datalanguage.com/features/daisy-architecture . (July 2018).\\nSunila Gollapudi. 2016. Practical Machine Learning . Packt Publishing, Birmingham, UK. https://books.google.ca/books?id=\\n3ywhjwEACAAJ\\nPradeep Menon. 2017. Demystifying Data Lake Architecture. https://www.datasciencecentral.com/profiles/blogs/\\ndemystifying-data-lake-architecture . (August 2017).\\nD. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Y oung, Jean-François Crespo,\\nand Dan Dennison. 2015. Hidden Technical Debt in Machine Learning Systems. In Annual Conference on Neural Information Processing\\nSystems . Neural Information Processing Systems Foundation, Montréal, QC, Canada, 2503–2511. http://papers.nips.cc/paper/\\n5656-hidden-technical-debt-in-machine-learning-systems\\nAjit Singh. 2019. Architecture of Data Lake. https://datascience.foundation/sciencewhitepaper/architecture-of-data-lake .\\n(April 2019).\\nDaniel Smith. 2017. Exploring Development Patterns in Data Science. https://www.theorylane.com/2017/10/20/\\nsome-development-patterns-in-data-science/ . (October 2017).\\nHironori Washizaki, Hiromu Uchida, Foutse Khomh, and Y ann-Gaël Guéhéneuc. 2019. Studying Software Engineering Patterns for Designing\\nMachine Learning Systems. In 10th International Workshop on Empirical Software Engineering in Practice . IEEE CS Press, Montréal, QC,\\nCanada, 1–6.\\nHironori Washizaki, Hiromu Uchida, Foutse Khomh, and Y ann-Gaël Guéhéneuc. 2020. Machine Learning Architecture and Design Patterns\\n(under review). (2020).\\nCarole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choudhury, Marat Dukhan, Kim M. Hazelwood, Eldad Isaac, Y angqing Jia, Bill\\nJia, Tommer Leyvand, Hao Lu, Yang Lu, Lin Qiao, Brandon Reagen, Joe Spisak, Fei Sun, Andrew Tulloch, Peter Vajda, Xiaodong Wang,\\nY anghan Wang, Bram Wasti, Yiming Wu, Ran Xian, Sungjoo Y oo, and Peizhao Zhang. 2019. Machine Learning at Facebook: Understanding\\n8https://git-scm.com/\\n9https://dvc.org/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 9Inference at the Edge. In 25th International Symposium on High Performance Computer Architecture . IEEE CS Press, Washington, DC,\\nUSA, 331–344. DOI:http://dx.doi.org/10.1109/HPCA.2019.00048\\nTianchen Wu. 2019. Version Control ML Model. https://towardsdatascience.com/version-control-ml-model-4adb2db5f87c .\\n(August 2019).\\nHaruki Y okoyama. 2019. Machine Learning System Architectural Pattern for Improving Operational Stability. In International Conference on Soft-\\nware Architecture Companion . IEEE CS Press, Hamburg, Germany, 267–274. DOI:http://dx.doi.org/10.1109/ICSA-C.2019.00055\\nAsianPLoP’20, MARCH 4–6, Taipei, Taiwan. Copyright 2020 is held by the author(s). HILLSIDE 978-1-941652-03-9\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 10\\nView publication stats'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S0GgIQs4Rps"
      },
      "source": [
        "Initialize the connection to your database:\n",
        "\n",
        "_(do not worry if you see a few warnings, it's just that the drivers are chatty about negotiating protocol versions with the DB.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zFBR5HnZSPmK"
      },
      "outputs": [],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7NxZYb4Rps"
      },
      "source": [
        "Create the LangChain embedding and LLM objects for later usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "TavS0AK2SLrL"
      },
      "outputs": [],
      "source": [
        "# Create the LangChain embedding and LLM objects for later usage:\n",
        "# Use a model known to be compatible with HuggingFaceEndpoint\n",
        "llm = ChatGroq(model_name = 'gemma2-9b-it', api_key=groq_API_KEY)\n",
        "embedding = HuggingFaceEmbeddings(model = 'sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMMx5Pm4Rpt"
      },
      "source": [
        "Create your LangChain vector store ... backed by Astra DB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bg9VAk4USQvU"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9FMAhKr77AVO"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BDHAyT7Gjr",
        "outputId": "770acbe2-3c12-44f1-d1ad-f1fd2f5e7cfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/359246513\\nSoftware-Engineering Design Patterns for Machine Learning Applications\\nArticle \\xa0\\xa0 in\\xa0\\xa0Comput er · Mar ch 2022\\nDOI: 10.1109/MC.2021.3137227\\nCITATIONS\\n58READS\\n2,898\\n7 author s, including:\\nHironori W ashiz aki\\nWaseda Univ ersity\\n445 PUBLICA TIONS \\xa0\\xa0\\xa03,670  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nYann-Gaël Guéhéneuc\\nConc ordia Univ ersity\\n368 PUBLICA TIONS \\xa0\\xa0\\xa011,389  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nHironori T akeuchi\\nMusashi Univ ersity\\n34 PUBLICA TIONS \\xa0\\xa0\\xa0181 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nSatoshi Ok uda\\nPrimestyle c o.\\n8 PUBLICA TIONS \\xa0\\xa0\\xa081 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Yann-Gaël Guéhéneuc  on 17 May 2022.',\n",
              " 'SEE PROFILE\\nSatoshi Ok uda\\nPrimestyle c o.\\n8 PUBLICA TIONS \\xa0\\xa0\\xa081 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Yann-Gaël Guéhéneuc  on 17 May 2022.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.Software Engineering Patterns for Machine Learning\\nApplications (SEP4MLA)\\nHIRONORI WASHIZAKI, Waseda University / National Institute of Informatics / System Information / eXmotion\\nFOUTSE KHOMH, Polytechnique Montréal\\nYANN-GAËL GUÉHÉNEUC, Concordia University\\nTo grasp the landscape of software engineering patterns for machine learning (ML) applications, a systematic literature review of both\\nacademic and gray literature is conducted to collect good and bad software-engineering practices in the form of patterns and anti-patterns for',\n",
              " 'academic and gray literature is conducted to collect good and bad software-engineering practices in the form of patterns and anti-patterns for\\nML applications. From the 32 scholarly documents and 48 gray documents identiﬁed, we extracted 12 ML architecture patterns, 13 ML design\\npatterns, and 8 ML anti-patterns. From these 33 ML patterns, we describe three major ML architecture patterns (“Data Lake”, “Distinguish\\nBusiness Logic from ML Models”, and “Microservice Architecture”) and one ML design pattern (“ML Versioning”) in the standard pattern\\nformat so that practitioners can (re)use them in their contexts.\\nCategories and Subject Descriptors: I.2.6 [ Artiﬁcial Intelligence ]: Learning— Machine learning ; D.2.11 [ Software Engineering ]: Software\\nArchitectures— Patterns',\n",
              " 'Categories and Subject Descriptors: I.2.6 [ Artiﬁcial Intelligence ]: Learning— Machine learning ; D.2.11 [ Software Engineering ]: Software\\nArchitectures— Patterns\\nAdditional Key Words and Phrases: Machine learning patterns\\nACM Reference Format:\\nWashizaki, H. Khomh, F . and Guéhéneuc, Y .-G. 2020. Core Machine Learning Architecture and Design Patterns. HILLSIDE Proc. of Conf. on\\nPattern Lang. of Prog. 0 (March 2020), 10 pages.\\n1. INTRODUCTION\\nResearchers and practitioners studying best practices strive to provide patterns that address software complexity\\nand quality issues in any type of software system. Recently, software systems with machine learning (ML)\\nalgorithms have become very popular. Because these ML applications are complex, they should beneﬁt from',\n",
              " 'algorithms have become very popular. Because these ML applications are complex, they should beneﬁt from\\npatterns that codify good/bad architectural and design practices during development. To help developers ensure\\nquality, such practices are often formalized as architecture and design patterns, which encapsulate reusable\\nsolutions to common problems within a given context.\\nTo grasp the landscape of software-engineering architecture and design patterns for machine-learning appli-\\ncations (SEP4MLA), we performed a systematic literature review (SLR) of both academic and gray literature to\\nThe authors would like to thank Prof. Naoshi Uchihira, Mr. Norihiko Ishitani, Dr. Takuo Doi, Dr. Shunichiro Suenaga, Mr. Y asuhiro Watanabe,',\n",
              " 'The authors would like to thank Prof. Naoshi Uchihira, Mr. Norihiko Ishitani, Dr. Takuo Doi, Dr. Shunichiro Suenaga, Mr. Y asuhiro Watanabe,\\nand Prof. Kazunori Sakamoto for their help. This work was supported by JST -Mirai Program Grant Number JP18077318, Japan.\\nAuthor’s address: H. Washizaki, 3-4-1 Okubo, Shinjuku-ku, Tokyo, Japan; email: washizaki@waseda.jp; F . Khomh, Polytechnique\\nMontréal, QC, Canada; email: foutse.khomh@polymtl.ca; Y.-G. Guéhéneuc, Concordia University, Montréal, QC, Canada; email: yann-\\ngael.gueheneuc@concordia.ca\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that',\n",
              " 'gael.gueheneuc@concordia.ca\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\\ncopies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page.\\nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission. A preliminary version of\\nthis paper was presented in a writers’ workshop at the 9thAsian Conference on Pattern Languages of Programs in 2020 (AsianPLoP’20).\\nAsianPLoP’20, MARCH 4–6, Taipei, Taiwan. Copyright 2020 is held by the author(s). HILLSIDE 978-1-941652-03-9Separation of Concerns \\nand Modularization of \\nML Components \\nHandshake T est the infrastructure independently',\n",
              " 'and Modularization of \\nML Components \\nHandshake T est the infrastructure independently \\nfrom the machine learning \\nReuse Code between Training \\nPipeline and Serving Pipeline Data-Algorithm-\\nServing-Evaluator Closed-Loop Intelligence \\nCanary ModelDaisy Architecture \\nEvent-driven ML MicroservicesMicroservice Architecture \\nData Lake \\nKappa Architecture Lambda Architecture \\nReexamine Experimental \\nBranches Periodically Parameter-Server \\nAbstraction \\nDescriptive Data Type \\nfor Rich Information Decouple Training Pipeline \\nfrom Production Pipeline ML VersioningDistinguish Business \\nLogic from \\nML Models \\nGateway Routing \\nArchitecture Undeclared Consumers \\nMultiple-Language \\nSmell \\nPlain-Old-Data \\nType Smell Abstraction Debt \\nPipeline Jungles \\nGlue Code Big Ass Script \\nArchitecture',\n",
              " 'ML Models \\nGateway Routing \\nArchitecture Undeclared Consumers \\nMultiple-Language \\nSmell \\nPlain-Old-Data \\nType Smell Abstraction Debt \\nPipeline Jungles \\nGlue Code Big Ass Script \\nArchitecture \\nAnti-pattern Architecture pattern \\nDesign pattern X Y   X can mitigate Y . \\nX Y    X uses Y in its solution. \\nX Y    X and Y can be combined.\\nX Y    X is similar to Y . Legend Design Holistically about Data \\nCollection and Feature Extraction \\nDead Experimental \\nCodepaths Federated Learning\\nSecure Aggregation Architecture \\npatterns \\nDesign \\npatterns \\nWrap Black-Box Packages \\ninto Common APIs Isolate and Validate \\nOutput of Model \\nX Y Patterns used by multiple participants.Fig. 1. Map to classify and relate patterns.',\n",
              " 'patterns \\nDesign \\npatterns \\nWrap Black-Box Packages \\ninto Common APIs Isolate and Validate \\nOutput of Model \\nX Y Patterns used by multiple participants.Fig. 1. Map to classify and relate patterns.\\ncollect SE good (bad) patterns for ML application systems and software [Washizaki et al .2019]. From the 32\\nscholarly documents and 48 gray documents identiﬁed in the SLR, 12 ML architecture patterns, 13 ML design\\npatterns, 3 ML anti-architecture patterns, and 5 ML anti-design patterns were extracted. Figure 1 shows a pattern\\nmap of these patterns and their relationships [Washizaki et al. 2020].\\nA survey of software-engineering and machine-learning developers at a workshop revealed that there are 7',\n",
              " 'map of these patterns and their relationships [Washizaki et al. 2020].\\nA survey of software-engineering and machine-learning developers at a workshop revealed that there are 7\\nmajor ML architectural patterns and 5 major ML design patterns among these 33 SEP4MLA. Multiple developers\\nanswered that they used the following ML architecture patterns: “Data-Algorithm-Serving-Evaluator”, “Data Lake“,\\n“Distinguish Business Logic from ML Models”, “Microservice Architecture”, “Event-driven ML Microservices”,\\n“Lambda Architecture”, and “Parameter-Server Abstraction” [Washizaki et al .2020]. They also used the following\\nML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Versioning”, “Test Infrastructure',\n",
              " 'ML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Versioning”, “Test Infrastructure\\nIndependently from ML ”, and “Wrap Black-box Packages into Common APIs” [Washizaki et al. 2020].\\nSince not all of the identiﬁed patterns are well documented in the standard pattern format, which includes clear\\nproblem statements and corresponding solution descriptions, herein we describe three major ML architecture\\npatterns and one ML design pattern in the standard pattern format so that practitioners can (re)use them in their\\ncontexts.\\n2. DATA LAKE\\n2.1 Source\\n[Gollapudi 2016; Menon 2017; Singh 2019]\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 22.2 Intent',\n",
              " 'contexts.\\n2. DATA LAKE\\n2.1 Source\\n[Gollapudi 2016; Menon 2017; Singh 2019]\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 22.2 Intent\\nCollect raw data for as long as possible and offer access to analytic algorithms, like ML algorithms.\\n2.3 Context\\nA lot of real-world data/information cannot be expressed easily through relational schemas. This data can be\\ndocuments (e.g., images), key/value pairs (e.g., users’ encrypted passwords) graphs (e.g., UML class diagrams),\\nor time series (e.g., temperatures from sensors). Although this data is not necessarily “big” data, it must be stored\\nto be analyzed asynchronously.\\n2.4 Problem\\nIn the traditional Data Warehouse architecture, all data is read from various sources by an ETL (Extract/Transform/Load)',\n",
              " 'to be analyzed asynchronously.\\n2.4 Problem\\nIn the traditional Data Warehouse architecture, all data is read from various sources by an ETL (Extract/Transform/Load)\\ntool, and is well structured based on a simpliﬁed data model to gain all the advantages of a data warehouse such\\nas fast and efﬁcient query processing [Daehn 2017]. In other words, semantics ﬁrst and content later [Daehn 2017].\\nIn practice, neither the types of analyses that will be performed nor the adopted frameworks can be foreseen.\\n2.5 Solution\\nFigure 2 shows the entire structure to solve the problem. Data, which ranges from structured to unstructured,\\nshould be stored as “raw” as possible into a data storage called a \"Data Lake\". A data lake should allow parallel',\n",
              " 'should be stored as “raw” as possible into a data storage called a \"Data Lake\". A data lake should allow parallel\\nanalyses of different types of data with various frameworks. Thus, a data lake should facilitate efﬁcient (time, space)\\nwriting of data from the data sources (e.g., sensors) and efﬁcient, parallel reading of the data for ML frameworks.\\nTo realize these features, the data lake must contain historical data and support the insert functionality.\\nThe approach of the data lake is the opposite of a data Warehouse. That is, content ﬁrst and semantics later\\n[Daehn 2017]. By giving up the update and delete functionalities, the overhead of an active database can be\\navoided without sacriﬁcing anything else [Daehn 2017].\\n2.6 Example',\n",
              " '[Daehn 2017]. By giving up the update and delete functionalities, the overhead of an active database can be\\navoided without sacriﬁcing anything else [Daehn 2017].\\n2.6 Example\\nApache Hadoop1and Azure Data Lake Storage Gen22implement data lakes. In addition, Amazon Simple Storage\\nService (S3)3can be used to implement a data lake, and Amazon provides a service called \"AWS Lake Formation\"4\\nto set up a secure data lake in days.\\n2.7 Discussion\\nData lakes must have clear access controls to allow certain users to write data and other users to read data. For\\nexample, sensors can write (not read), while a control system can read (not write). Analyses applying on a data\\nlake must ﬁrst transfer (while transforming) the relevant data from the data lake into a data warehouse. Then the',\n",
              " 'lake must ﬁrst transfer (while transforming) the relevant data from the data lake into a data warehouse. Then the\\ndata warehouse can be completely rebuilt using a transformation tool such as Apache Spark5.\\n2.8 Related Patterns\\n“Distinguish Business Logic from ML Models” (see Section 3) and Gateway Routing Architecture (not described\\nhere).\\n1https://hadoop.apache.org/\\n2https://azure.microsoft.com/solutions/data-lake/\\n3https://aws.amazon.com/s3/\\n4https://aws.amazon.com/lake-formation/\\n5https://spark.apache.org/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 3Unstructured \\ndata Structured \\ndata Data \\nsource Data \\nsource \\nML framework Data \\nsource Data \\nsource \\nML framework ML framework Other data \\nanalytics Insert-only \\ndata storage \\nTransformation tool',\n",
              " 'data Structured \\ndata Data \\nsource Data \\nsource \\nML framework Data \\nsource Data \\nsource \\nML framework ML framework Other data \\nanalytics Insert-only \\ndata storage \\nTransformation tool \\nData \\nwarehouse Fig. 2. Structure of the Data Lake pattern\\n3. DISTINGUISH BUSINESS LOGIC FROM ML MODELS\\n3.1 Source\\n[Y okoyama 2019]\\n3.2 Intent\\nSeparate the overall business logic of the ML application from the actual used ML models.\\n3.3 Context\\nML applications often use different ML frameworks and associated models (trained in previous, off-line phases).\\nThe frameworks and models play roles in the wider business logic.\\n3.4 Problem\\nThe business logic depends on the results of the models, which may fail for a variety of reasons (as the rest of the',\n",
              " 'The frameworks and models play roles in the wider business logic.\\n3.4 Problem\\nThe business logic depends on the results of the models, which may fail for a variety of reasons (as the rest of the\\nbusiness logic can too). Hence, the overall business logic should be isolated as much as possible from the ML\\nmodels. This way, they can be changed/overridden when necessary without impacting the rest of the business\\nlogic.\\n3.5 Solution\\nFigure 3 shows the entire structure to solve the problem.\\n(1)Separate the business logic and the inference engine, loosely coupling the business logic and ML-speciﬁc\\ndataﬂows.\\n(2)Use loggers to monitor the behavior of the ML models.',\n",
              " '(1)Separate the business logic and the inference engine, loosely coupling the business logic and ML-speciﬁc\\ndataﬂows.\\n(2)Use loggers to monitor the behavior of the ML models.\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 4(3)Set-up alarms for changes in the data distributions that may invalidate the ML models throughout the execution\\nof the ML application.\\nData Layer Logic Layer Presentation Layer \\nUser \\nInterface Database \\nData \\nCollection Data Lake Business \\nLogic \\nData \\nProcessing \\nInference \\nEngine Real World Business Logic Specific ML Specific \\nArchitectural Layers \\nDeployed as ML System Business Logic Data Flow \\nML Runtime Data Flow \\nML Development Data Flow Legend \\nFig. 3. Structure of the Distinguish Business Logic from ML Model pattern.',\n",
              " 'Architectural Layers \\nDeployed as ML System Business Logic Data Flow \\nML Runtime Data Flow \\nML Development Data Flow Legend \\nFig. 3. Structure of the Distinguish Business Logic from ML Model pattern.\\n3.6 Example\\nFigure 4 presents an example of the pattern in a Slack-based Chatbot system [Washizaki et al .2020]. In the\\nsystem, there is clear separation between the Chatbot service (as the business logic) and the underlying ML\\ncomponents.\\n3.7 Discussion\\nThis pattern distinguishes failures from the business logic and the ML models so that ML models can be changed\\nwithout impacting the rest of the logic.\\n3.8 Related Patterns\\n“Gateway Routing Architecture” and “Closed-loop Intelligence” (not described here).\\n4. MICROSERVICE ARCHITECTURE\\n4.1 Source\\n[Everett 2018; Smith 2017]\\n4.2 Intent',\n",
              " '3.8 Related Patterns\\n“Gateway Routing Architecture” and “Closed-loop Intelligence” (not described here).\\n4. MICROSERVICE ARCHITECTURE\\n4.1 Source\\n[Everett 2018; Smith 2017]\\n4.2 Intent\\nDeﬁne consistent input and output data and provide well-deﬁned services to use for ML frameworks.\\n4.3 Context\\nML applications often use different ML frameworks, which are developed independently by ML researchers. ML\\nresearchers are experts in ML but not in the development of frameworks. Moreover, each team of researchers has\\na different idea about their working frameworks. Thus, ML frameworks are heterogeneous in terms of forms (APIs)\\nand contents (data structures, algorithms).\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 5Data Layer Logic Layer Presentation Layer',\n",
              " 'and contents (data structures, algorithms).\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 5Data Layer Logic Layer Presentation Layer \\nUser Interface \\n(Chatbot UI) \\nWeb App \\nFront-end Slack Business Logic \\n(Chatbot Logic) \\nWeb App \\nBack-end Slack \\nData Collection \\n(Dataset) \\nDatasets Nagoya Univ. \\nConversation \\nCorpus Data Processing \\n(Text to Vector Transformer) \\nNN Model \\npre- and post-\\nprocessing TensorFlow \\nInference Engine \\n(Language Model) \\nNN Model TensorFlow Database \\n(Previous Q&A Store) \\nDB Server (None) \\nData Lake \\n(V ectorized Corpus) \\nWord \\nV ector TensorFlow\\n(Text) Users \\nData \\nSource Input \\nOutput \\nDatasets \\nML Input ML Output \\nArchitectural Elements \\n(Example Role as Chatbot) \\nWhat How \\nBusiness Logic Data Flow',\n",
              " 'Word \\nV ector TensorFlow\\n(Text) Users \\nData \\nSource Input \\nOutput \\nDatasets \\nML Input ML Output \\nArchitectural Elements \\n(Example Role as Chatbot) \\nWhat How \\nBusiness Logic Data Flow \\nML Development Data Flow ML Runtime Data Flow Input Data \\nOutput Data \\nInput Data \\nDatasets Word \\nVector \\nLegend Fig. 4. Example of a Chatbot System Architecture by applying the “Distinguish Business Logic from ML Model” pattern.\\nA wide variety of these frameworks are available in open-source at places like mloss.org , or from in-house\\ncode, proprietary packages, and cloud-based platforms. ML applications may use one framework but later change\\nfor another framework.\\n4.4 Problem\\nIt is impossible to be familiar with all ML frameworks. In addition, data scientists may be unable to install and run',\n",
              " 'for another framework.\\n4.4 Problem\\nIt is impossible to be familiar with all ML frameworks. In addition, data scientists may be unable to install and run\\nthese frameworks locally. Thus, ML applications may be conﬁned to “known” ML frameworks, and opportunities for\\nmore appropriate frameworks may be missed.\\n4.5 Solution\\nFigure 5 shows the entire structure to solve the problem. Data scientists working with or providing ML frameworks\\ncan make these frameworks available through micro-services. Micro-services are ﬁne-grained and accessible\\nthrough simple protocols. Thus, data scientists can offer access to their ML frameworks through micro-services so\\nthat any ML application can beneﬁt from their frameworks without having to (1) install them and (2) maintain them\\nwhen new versions are available.',\n",
              " 'that any ML application can beneﬁt from their frameworks without having to (1) install them and (2) maintain them\\nwhen new versions are available.\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 6Client (User Interface) \\nML framework \\nDB ML service ML service Routing \\nservice \\nMicroservice \\nDB Microservice\\nDB Fig. 5. Structure of the Microservices Architecture pattern.\\n4.6 Example\\nAmazon SageMaker6(see also AWS DeepRacer7)\\n4.7 Discussion\\nThe beneﬁt of microservices is that data scientists, who may not be experts in software engineering, do not have to\\nworry about installing/maintaining ML frameworks. They can also use the same set of microservices in different ML',\n",
              " 'worry about installing/maintaining ML frameworks. They can also use the same set of microservices in different ML\\napplications. Similarly, microservices can be used by different, competing ML applications. Hence, microservice\\nproviders can capitalize on their investment.\\nUnlike “Wrap Black-Box Packages into Common APIs”, ML applications depend on microservices and cannot\\nimmediately replace one ML framework with another (unless the microservice provider offers different frameworks).\\nThus, ML applications become dependent upon one service provider.\\n4.8 Related Patterns\\n“Daisy Architecture”, “Event-driven ML Microservices”, “Wrap Black-box Packages into Common APIs”, and\\n‘Separation of Concerns and Modularization of ML Components” (not described here).\\n5. ML VERSIONING\\n5.1 Source',\n",
              " '‘Separation of Concerns and Modularization of ML Components” (not described here).\\n5. ML VERSIONING\\n5.1 Source\\n[Wu et al. 2019; Amershi et al. 2019; Sculley et al. 2015]\\n5.2 Intent\\nVersion ML models like any other software artifacts are tested for regressions and replication ease.\\n5.3 Context\\nML applications may use (1) several models that (2) can change over time (new training).\\n6https://aws.amazon.com/sagemaker/\\n7https://aws.amazon.com/deepracer/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 75.4 Problem\\nML models and their different versions may change the behavior of the overall ML application.\\n5.5 Solution\\nFigure 6 shows the entire structure to solve the problem. Record the ML model structure, training dataset, training',\n",
              " '5.5 Solution\\nFigure 6 shows the entire structure to solve the problem. Record the ML model structure, training dataset, training\\nsystem and analytical code to ensure a reproducible training process and an inference process. Similar to other\\nsoftware artifacts, ML models should be versioned so that they can be tested and rolled back in case of regression.\\nML model \\nDataset \\nCode Version \\nVersion Control and Configuration \\nManagement …\\n…\\nFig. 6. Structure of the ML Versioning pattern.\\n5.6 Example\\nIn the Eclipse Foundation library DP4J, models can be saved and loaded from the ﬁle system using the org.\\ndeeplearning4j.rl4j.policy.DQNPolicy.save(String) andorg.deeplearning4j.rl4j.policy.DQNPolicy.',\n",
              " 'In the Eclipse Foundation library DP4J, models can be saved and loaded from the ﬁle system using the org.\\ndeeplearning4j.rl4j.policy.DQNPolicy.save(String) andorg.deeplearning4j.rl4j.policy.DQNPolicy.\\nload(String) methods. These methods can be used not only during training/production but also during versioning\\nto store models and version them as any other software artifacts.\\n5.7 Discussions\\nTo the best of our knowledge, previous works have not studied the performance and the sustainability of serialized\\nML models. It is unknown whether saving/loading models has a negative impact on the performances of ML\\napplications. In addition, the long-term abilities to load and use ML models with new versions of (different) ML\\nframeworks are unknown.',\n",
              " 'applications. In addition, the long-term abilities to load and use ML models with new versions of (different) ML\\nframeworks are unknown.\\nAlthough versioning the control dataset, training system, analytical code, and corresponding ML models is\\nrecommended to ensure the reproducibility, versioning all of them in a sophisticated and systematic manner\\ncan be difﬁcult due to the size of the dataset and complicated conﬁgurations among the hyperparameters,\\ntraining/inference code, etc. Two layers of version control can mitigate the issue by handling code and metadata\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 8(of dataset and ML models) in a code storage such as Git8, and handling large dataset and ML models in a data',\n",
              " 'Software Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 8(of dataset and ML models) in a code storage such as Git8, and handling large dataset and ML models in a data\\nstorage such as DVC (Data Version Control)9[Wu 2019].\\n5.8 Related Patterns\\n“Test the Infrastructure Independently from the Machine Learning” and “Canary Model” (not described here).\\n6. CONCLUSION\\nHerein three major ML architecture patterns (“Data Lake“, “Distinguish Business Logic from ML Models”, and\\n“Microservice Architecture”) and one major ML design pattern (“ML Versioning”) are described. These pattern are\\nfrom a set of 33 patterns identiﬁed through a SLR. In the future, we plan to write all 33 patterns in the standard',\n",
              " 'from a set of 33 patterns identiﬁed through a SLR. In the future, we plan to write all 33 patterns in the standard\\npattern format to help developers adopt good practices and avoid bad practices described by these patterns.\\nAcknowledgement\\nWe are grateful to shepherd Prof. Nien Lin Hsueh for the careful review that improve this paper. We thank Mr.\\nHiromu Uchida, Prof. Naoshi Uchihira, Mr. Norihiko Ishitani, Dr. Takuo Doi, Dr. Shunichiro Suenaga, Mr. Y asuhiro\\nWatanabe and Prof. Kazunori Sakamoto for their help. This work was supported by JST-Mirai Program Grant\\nNumber JP18077318, Japan.\\nReceived December 2019; revised ; accepted\\nREFERENCES\\nSaleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald C. Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and',\n",
              " 'Received December 2019; revised ; accepted\\nREFERENCES\\nSaleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald C. Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and\\nThomas Zimmermann. 2019. Software engineering for machine learning: a case study. In Proceedings of the 41st International Conference\\non Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2019, Montreal, QC, Canada, May 25-31, 2019 . 291–300.\\nDOI:http://dx.doi.org/10.1109/ICSE-SEIP.2019.00042\\nWerner Daehn. 2017. A future-proof Big Data Architecture. https://blogs.sap.com/2017/10/10/\\nfuture-proof-big-data-architecture/ . (October 2017).\\nJulian Everett. 2018. Daisy Architecture. https://datalanguage.com/features/daisy-architecture . (July 2018).',\n",
              " 'future-proof-big-data-architecture/ . (October 2017).\\nJulian Everett. 2018. Daisy Architecture. https://datalanguage.com/features/daisy-architecture . (July 2018).\\nSunila Gollapudi. 2016. Practical Machine Learning . Packt Publishing, Birmingham, UK. https://books.google.ca/books?id=\\n3ywhjwEACAAJ\\nPradeep Menon. 2017. Demystifying Data Lake Architecture. https://www.datasciencecentral.com/profiles/blogs/\\ndemystifying-data-lake-architecture . (August 2017).\\nD. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Y oung, Jean-François Crespo,\\nand Dan Dennison. 2015. Hidden Technical Debt in Machine Learning Systems. In Annual Conference on Neural Information Processing',\n",
              " 'and Dan Dennison. 2015. Hidden Technical Debt in Machine Learning Systems. In Annual Conference on Neural Information Processing\\nSystems . Neural Information Processing Systems Foundation, Montréal, QC, Canada, 2503–2511. http://papers.nips.cc/paper/\\n5656-hidden-technical-debt-in-machine-learning-systems\\nAjit Singh. 2019. Architecture of Data Lake. https://datascience.foundation/sciencewhitepaper/architecture-of-data-lake .\\n(April 2019).\\nDaniel Smith. 2017. Exploring Development Patterns in Data Science. https://www.theorylane.com/2017/10/20/\\nsome-development-patterns-in-data-science/ . (October 2017).\\nHironori Washizaki, Hiromu Uchida, Foutse Khomh, and Y ann-Gaël Guéhéneuc. 2019. Studying Software Engineering Patterns for Designing',\n",
              " 'some-development-patterns-in-data-science/ . (October 2017).\\nHironori Washizaki, Hiromu Uchida, Foutse Khomh, and Y ann-Gaël Guéhéneuc. 2019. Studying Software Engineering Patterns for Designing\\nMachine Learning Systems. In 10th International Workshop on Empirical Software Engineering in Practice . IEEE CS Press, Montréal, QC,\\nCanada, 1–6.\\nHironori Washizaki, Hiromu Uchida, Foutse Khomh, and Y ann-Gaël Guéhéneuc. 2020. Machine Learning Architecture and Design Patterns\\n(under review). (2020).\\nCarole-Jean Wu, David Brooks, Kevin Chen, Douglas Chen, Sy Choudhury, Marat Dukhan, Kim M. Hazelwood, Eldad Isaac, Y angqing Jia, Bill\\nJia, Tommer Leyvand, Hao Lu, Yang Lu, Lin Qiao, Brandon Reagen, Joe Spisak, Fei Sun, Andrew Tulloch, Peter Vajda, Xiaodong Wang,',\n",
              " 'Jia, Tommer Leyvand, Hao Lu, Yang Lu, Lin Qiao, Brandon Reagen, Joe Spisak, Fei Sun, Andrew Tulloch, Peter Vajda, Xiaodong Wang,\\nY anghan Wang, Bram Wasti, Yiming Wu, Ran Xian, Sungjoo Y oo, and Peizhao Zhang. 2019. Machine Learning at Facebook: Understanding\\n8https://git-scm.com/\\n9https://dvc.org/\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 9Inference at the Edge. In 25th International Symposium on High Performance Computer Architecture . IEEE CS Press, Washington, DC,\\nUSA, 331–344. DOI:http://dx.doi.org/10.1109/HPCA.2019.00048\\nTianchen Wu. 2019. Version Control ML Model. https://towardsdatascience.com/version-control-ml-model-4adb2db5f87c .\\n(August 2019).',\n",
              " 'USA, 331–344. DOI:http://dx.doi.org/10.1109/HPCA.2019.00048\\nTianchen Wu. 2019. Version Control ML Model. https://towardsdatascience.com/version-control-ml-model-4adb2db5f87c .\\n(August 2019).\\nHaruki Y okoyama. 2019. Machine Learning System Architectural Pattern for Improving Operational Stability. In International Conference on Soft-\\nware Architecture Companion . IEEE CS Press, Hamburg, Germany, 267–274. DOI:http://dx.doi.org/10.1109/ICSA-C.2019.00055\\nAsianPLoP’20, MARCH 4–6, Taipei, Taiwan. Copyright 2020 is held by the author(s). HILLSIDE 978-1-941652-03-9\\nSoftware Engineering Patterns for Machine Learning Applications (SEP4MLA) — Page 10\\nView publication stats']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1WK54-74Rpt"
      },
      "source": [
        "### Load the dataset into the vector store\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX5BECsdSUUM",
        "outputId": "485efbb6-fb53-4351-b947-e3299affa110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 39 headlines.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "astra_vector_store.add_texts(texts)\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJp8yPF4Rpt"
      },
      "source": [
        "### Run the QA cycle\n",
        "\n",
        "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"▪\" button on the top toolbar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJugrh7SX3C",
        "outputId": "9bd13ccd-0a03-41b4-9141-90ed90716800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): design pattern for ML engineers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "QUESTION: \"design pattern for ML engineers\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER: \"According to the text provided, the ML design patterns are:\n",
            "\n",
            "* \"Handshake\"\n",
            "* \"Isolate and Validate Output of Model\"\n",
            "* \"ML Versioning\"\n",
            "* \"Test Infrastructure Independently from ML\"\n",
            "* \"Wrap Black-box Packages into Common APIs\" \n",
            "\n",
            "\n",
            "Let me know if you have any other questions.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n",
            "    [0.8480] \"ML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Version ...\"\n",
            "    [0.8480] \"ML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Version ...\"\n",
            "    [0.8480] \"ML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Version ...\"\n",
            "    [0.8480] \"ML design patterns: “Handshake”, “Isolate and Validate Output of Model”, “ML Version ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
